{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20388b80-8771-4e4f-92b6-93fe826c1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mg5qs_import as qs\n",
    "import numpy as np\n",
    "import os\n",
    "import concurrent\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c6cbc-79e3-4e9d-9cba-6b1666636154",
   "metadata": {},
   "source": [
    "### Storing data and varying multiple parameters\n",
    "\n",
    "\n",
    "This example will demonstrate a way to store data at the time of generation using Python's built-in binary file writer, pickle. This approach has many benefits including: arbitrarily large runs with no concern to depleting system resources (data not stored in memory), safety (data is stored at the time of generation), and multithreading compatibility. \n",
    "\n",
    "This example includes:\n",
    "- looping over multiple model parameters\n",
    "- use of pickle to store pT data\n",
    "- reading pickle files\n",
    "- reassociating data with corresponding model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa3668-02d7-4dd3-b8e0-53bfde70cac8",
   "metadata": {},
   "source": [
    "### 1. Generate a MadGraph framework\n",
    "\n",
    "**1.1 call run_MG5**\n",
    "\n",
    "For the purposes of this example, the proc_card and run_card will not be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e44983-07e7-47ae-be2d-fd39be7b57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name, FRAMEWORK_PATH = qs.run_MG5(qs.MG5_PATH, qs.INPUT_PATH, proc_card_name='proc_card.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c3313-abcc-4007-8cd6-fa72516ebc88",
   "metadata": {},
   "source": [
    "### 2. Generate LHEs varying multiple parameters \n",
    "\n",
    "**2.1 load param_card as ParamCard object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecf858-e6ce-4a2d-ab04-44c2c3105243",
   "metadata": {},
   "outputs": [],
   "source": [
    "card = qs.ParamCard(FRAMEWORK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191243bf-4feb-4332-9f13-3c3b707453f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "card.dfs()['MASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583f4ca-a373-4df4-95d0-18b6e2ea59e7",
   "metadata": {},
   "source": [
    "**2.2 Vary Higgs mass and mass of the Z-boson while generating LHEs**\n",
    "\n",
    "MH_MZ will be required for reassociating the runs to their respective parameter values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50a7e6-3a23-4148-9cd8-4ccb248e85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MHs = [42, 125]\n",
    "MZs = [42, 91.188] # the parameter values to be looped over\n",
    "count = 0 \n",
    "MH_MZ = {} # nested dict keyed to parameter values, used for run association \n",
    "\n",
    "for MH in MHs:\n",
    "    for MZ in MZs:\n",
    "        if not MH in MH_MZ.keys():\n",
    "            MH_MZ[MH] = {}\n",
    "        MH_MZ[MH][MZ] = count # dict[dict] to assocate params with run numbers\n",
    "        count += 1 \n",
    "        card.set_value('MASS', 25, MH)\n",
    "        card.set_value('MASS', 23, MZ)\n",
    "        print('Working on MH =',MH, '& MZ =',MZ,'...')\n",
    "        qs.generate_LHE(card, FRAMEWORK_PATH)\n",
    "print('done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a354391-6277-4e69-942c-1e5f6956456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MH_MZ # parameter values are associated with run number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec9820-8222-47f2-97b8-ce4db7681c27",
   "metadata": {},
   "source": [
    "### 3. Generate pT while storing to pickle files\n",
    "\n",
    "**3.1 get LHEs, shower using Pythia, and store pT in pickle files**\n",
    "\n",
    "This process can generate any quantity of pT values, limited only by space in the file system (instead of in memory). The overhead of reading and writing pickle files is low, and the files are very small (containing only pT values, and no other data from the shower). This is in contrast to the standard .hepmc files that are necessarily large, each containing every detail of every particle in the shower (on the order of tens of gigabytes, compared to 1-2 megabytes for a pickle file). Also, intercepting the pT values at runtime eliminates the need to post-process .hepmc files to calculate pT.\n",
    "\n",
    "In this example, each pickle file contains pT associated with a unique set of parameters, but it is equally easy to produce many runs with the same parameters, allowing for generation of very large data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758487e-b147-4ec4-99d1-23b9f6e83506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = Path('pT_tau_runs')  # output path relative to Jupyter\n",
    "cpu_cores = 10                    # set an appropriate value based on CPU hardware\n",
    "\n",
    "TAU = 15 # Particle ID for Tau\n",
    "LHEs = qs.get_LHEs(FRAMEWORK_PATH)\n",
    "\n",
    "# create output path if it does not exist\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# function to process a single LHE file, storing result in a pickle file\n",
    "def process_LHE(n, LHE, PID):\n",
    "    pTs = qs.generate_pT(PID, LHE)\n",
    "    fname = FRAMEWORK_PATH.name + '.' + str(n) + '.pkl'\n",
    "    with open(output_dir / fname, 'wb') as f:\n",
    "        pickle.dump(pTs, f)\n",
    "        f.close()\n",
    "\n",
    "# run multiple processes in parallel\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=cpu_cores) as executor:\n",
    "    futures = {executor.submit(process_LHE, i, LHE, TAU): i for i, LHE in enumerate(LHEs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761e1e9-1d02-4279-82fe-9833bcd47b23",
   "metadata": {},
   "source": [
    "**3.2 continue to handle allocation of data to a corresponding run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b6c68-3e85-4170-af2a-d48bdd49578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve pT values from pickle files\n",
    "def get_pT(mh, mz):\n",
    "    n = MH_MZ[mh][mz]\n",
    "    fname = FRAMEWORK_PATH.name + '.' + str(n) + '.pkl'\n",
    "    with open(output_dir / fname, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "results = []\n",
    "for MH in MHs:\n",
    "    for MZ in MZs:\n",
    "        results.append((MH, MZ, get_pT(MH, MZ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f22b1b-7315-4b76-b13a-3fcfd43edbe0",
   "metadata": {},
   "source": [
    "**3.3 graph results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fa3f9-0f8d-47d8-b294-b0491ca2ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(results), figsize=(7, len(results)*6))\n",
    "# adapter to graphing code from prior example (fun CS exercise) \n",
    "i_j = [[i, j] for i in range(len(MHs)) for j in range(len(MZs))]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    ax[i].hist(results[i][2][1], bins=30)\n",
    "    ax[i].set_title(f'MH = {MHs[i_j[i][0]]}, MZ = {MZs[i_j[i][1]]}')\n",
    "    ax[i].set_yscale('log')\n",
    "    ax[i].set_xlabel(\"pT (GeV)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (My Custom Kernel)",
   "language": "python",
   "name": "my_custom_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
